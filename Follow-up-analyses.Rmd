---
title: "Follow-up analyses with updated random-level effects"
output: html_notebook
---

```{r}
library(tidyr)
library(brms)
library(ggplot2)
library(ggridges)
```

```{r}
#Phase 1: MCMC analysis by listener accent using stimulus as random effect

bprior <- bprior <- c(prior_string("normal(0,1)", class = "b"))
detection.model1 <- brm(Correct~(Accent-1)+(1|Question|Participant), prior=bprior, data=accent.data.long, family=bernoulli)
detection.model1.post <- posterior_samples(detection.model1)

#computing probability intervals

quantile(logistic(detection.model1.post$b_AccentBelfast),c(0.025,0.975))
quantile(logistic(detection.model1.post$b_AccentBristol),c(0.025,0.975))
quantile(logistic(detection.model1.post$b_AccentDublin),c(0.025,0.975))
quantile(logistic(detection.model1.post$b_AccentEssex),c(0.025,0.975))
quantile(logistic(detection.model1.post$b_AccentGlasgow),c(0.025,0.975))
quantile(logistic(detection.model1.post$b_AccentNortheast),c(0.025,0.975))
quantile(logistic(detection.model1.post$b_AccentRP),c(0.025,0.975))
```

```{r}
#Phase 2: MCMC analysis by whether participant spoke in a study accent using stimulus as random effect

detection.model2 <- brm(Correct~(Study.accent-1)+(1|Question|Participant), prior=bprior, data=phase2.clean.long, family=bernoulli, chains = 6)
detection.model2.post <- posterior_samples(detection.model2)

#summary

summary(detection.model2)

#compute PIs

quantile(logistic(detection.model2.post$b_Study.accent0),c(0.025,0.975))
quantile(logistic(detection.model2.post$b_Study.accent1),c(0.025,0.975))

#compute the difference
quantile(logistic(detection.model2.post$b_Study.accent0)-logistic(detection.model2.post$b_Study.accent1),c(0.025,0.975))

```

```{r}
#new amalgamated dataset

updated.phase1.data <- phase1.data.long
updated.phase1.data$Question <- accent.data.long$Question
updated.phase2.data <- phase2.data.long
updated.phase2.data$Question <- phase2.clean.long$Question

updated.updated.amalgamated.accent.data <- rbind(updated.phase1.data,updated.phase2.data)
updated.updated.amalgamated.accent.data$Participant <- factor(updated.updated.amalgamated.accent.data$Participant)


```

```{r}
#updated amalgamate model of listener speaking naturally in a study accent as a fixed effect and question as an additional random effect

detection.model3 <- brm(Correct~(Study.accent-1)+(1|Question|Participant), prior=bprior, data=updated.amalgamated.accent.data, family=bernoulli, chains=6)
detection.model3.post <- posterior_samples(detection.model3)

summary(detection.model3)

quantile(logistic(detection.model3.post$b_Study.accent0),c(0.025,0.975))
quantile(logistic(detection.model3.post$b_Study.accent1),c(0.025,0.975))
quantile(logistic(detection.model3.post$b_Study.accent0)-logistic(detection.model3.post$b_Study.accent1),c(0.025,0.975))


```

```{r}
#updated  model for all variables of interest

detection.model.accent.updated <- brm(Correct~(Study.accent-1):(Sentence.accent-1)+(1|Question|Participant), prior=bprior, data=updated.amalgamated.accent.data, family=bernoulli, chains=6)
detection.model.accent.updated.post <- posterior_samples(detection.model.accent)

paste("Belfast")
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentBelfast`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentBelfast`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentBelfast`)-logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentBelfast`),c(0.025,0.975))

paste("Bristol")
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentBristol`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentBristol`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentBristol`)-logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentBristol`),c(0.025,0.975))

paste("Dublin")
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentDublin`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentDublin`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentDublin`)-logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentDublin`),c(0.025,0.975))

paste("Essex")
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentEssex`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentEssex`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentEssex`)-logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentEssex`),c(0.025,0.975))

paste("Glasgow")
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentGlasgow`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentGlasgow`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentGlasgow`)-logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentGlasgow`),c(0.025,0.975))

paste("Northeast")
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentNortheast`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentNortheast`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentNortheast`)-logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentNortheast`),c(0.025,0.975))

paste("RP")
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentRP`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentRP`),c(0.025,0.975))
quantile(logistic(detection.model.accent.updated.post$`b_Study.accent0:Sentence.accentRP`)-logistic(detection.model.accent.updated.post$`b_Study.accent1:Sentence.accentRP`),c(0.025,0.975))
```

```{r}
#updated diversity model with question as random-level effect

updated.amalgamated.accent.data$White <- NA
updated.amalgamated.accent.data$White[updated.amalgamated.accent.data$Accent=="Belfast"] <- 96.43
updated.amalgamated.accent.data$White[updated.amalgamated.accent.data$Accent=="Bristol"] <- 84.00
updated.amalgamated.accent.data$White[updated.amalgamated.accent.data$Accent=="Dublin"] <- 90.40
updated.amalgamated.accent.data$White[updated.amalgamated.accent.data$Accent=="Essex"] <- 93.30
updated.amalgamated.accent.data$White[updated.amalgamated.accent.data$Accent=="Glasgow"] <- 88.40
updated.amalgamated.accent.data$White[updated.amalgamated.accent.data$Accent=="Northeast"] <- 85.30
updated.amalgamated.accent.data$White[updated.amalgamated.accent.data$Accent=="RP"] <- 59.70

#remove individuals where study.accent = 0

amalgamated.accent.data.study.only <- subset(updated.amalgamated.accent.data, Study.accent==1)

#add mean probability of correct answer at city level from detection model

amalgamated.accent.data.study.only$Probability <- NA
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Belfast"] <- diversity[1,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Bristol"] <- diversity[2,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Dublin"] <- diversity[3,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Essex"] <- diversity[4,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Glasgow"] <- diversity[5,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Northeast"] <- diversity[6,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="RP"] <- diversity[7,3]

detection.model.accent.diversity.b <- brm(Correct~White+(1|Question|Participant), data=subset(amalgamated.accent.data.study.only, Sentence.accent!="Essex"), family="bernoulli")

logistic(-1.26+0.03*50)
logistic(-1.26+0.03*95)
```
```{r}
#running ethnic diversity as glmer for confirmation

library(lme4)
library(lmerTest)
detection.model.accent.diversity.c <- glmer(Correct~White+(1|Accent/Participant), data=subset(amalgamated.accent.data.study.only, Sentence.accent!="Essex"), family=binomial)
summary(detection.model.accent.diversity.c)
```
```{r}
exp(fixef(detection.model.accent.diversity.c))
exp(confint(detection.model.accent.diversity.c, method="Wald"))
```

```{r}
library(effects)
effects_c <- effects::effect(term= "White", mod= detection.model.accent.diversity.c)
effects_c <- as.data.frame(effects_c)
summary(effects_c) 
```

```{r}
library(sjPlot)
sjPlot::tab_model(detection.model.accent.diversity.c, 
                  show.re.var= TRUE)

library(ggplot2)
ggplot()+
  geom_point(data=effects_c, aes(x=White, y=fit), color="blue")+
  geom_line(data=effects_c, aes(x=White, y=fit), color="blue")+
  geom_ribbon(data=effects_c, aes(x=White, ymin=lower, ymax=upper), alpha= 0.3, fill="blue")+
  labs(x="Percentage of individuals identifying as White",y="Probability of a correct response")
  
```

```{r}
#test without RP

#add mean probability of correct answer at city level from detection model

amalgamated.accent.data.study.only$Probability <- NA
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Belfast"] <- diversity[1,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Bristol"] <- diversity[2,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Dublin"] <- diversity[3,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Essex"] <- diversity[4,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Glasgow"] <- diversity[5,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="Northeast"] <- diversity[6,3]
amalgamated.accent.data.study.only$Probability[amalgamated.accent.data.study.only$Accent=="RP"] <- diversity[7,3]

detection.model.accent.diversity.d <- brm(Correct~White+(1|Question|Participant), data=subset(amalgamated.accent.data.study.only, Sentence.accent!="Essex" & Sentence.accent!="RP"), family="bernoulli")

logistic(-1.26+0.03*50)
logistic(-1.26+0.03*95)
```

```{r}
#running ethnic diversity as glmer for confirmation

library(lme4)
library(lmerTest)
detection.model.accent.diversity.e <- glmer(Correct~White+(1|Accent/Participant), data=subset(amalgamated.accent.data.study.only, Sentence.accent!="Essex" & Sentence.accent!="RP"), family=binomial)
summary(detection.model.accent.diversity.e)
```

```{r}
exp(fixef(detection.model.accent.diversity.e))
exp(confint(detection.model.accent.diversity.e, method="Wald"))
```
```{r}
library(effects)
effects_e <- effects::effect(term= "White", mod= detection.model.accent.diversity.e)
effects_e <- as.data.frame(effects_e)
summary(effects_e) 
```

```{r}
library(sjPlot)
sjPlot::tab_model(detection.model.accent.diversity.e, 
                  show.re.var= TRUE)
```

```{r}
library(ggplot2)
ggplot()+
  geom_point(data=effects_e, aes(x=White, y=fit), color="blue")+
  geom_line(data=effects_e, aes(x=White, y=fit), color="blue")+
  geom_ribbon(data=effects_e, aes(x=White, ymin=lower, ymax=upper), alpha= 0.3, fill="blue")+
  labs(x="Percentage of individuals identifying as White",y="Probability of a correct response")
```  
